{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028c0e7-85a9-428c-b08a-83bf7daf984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict, List\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f95f25-5118-400c-93e3-63257c0b1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52113f16-570f-4e5e-ae9e-93a17c52b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "# import torchinfo\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import RandAugment\n",
    "from torch.autograd.grad_mode import inference_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bc43b-2859-4a08-a1ec-00cfe49896e5",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6f343-5bc4-4128-a312-7fe09beeb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(path):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img.verify()   # verify the contents of a file. If the file is broken\n",
    "        return True\n",
    "    except (IOError, SyntaxError, Image.UnidentifiedImageError):\n",
    "        print(f\"Skipping corrupted file: {path}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a1914-1ec1-4862-a70d-77d3baecbe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"./data/data/train\")\n",
    "test_path = Path(\"./data/data/test\")\n",
    "\n",
    "def get_data(train_path, test_path):\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    train_transform.transforms.insert(0, RandAugment(num_ops=2, magnitude=9))\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    train_data = ImageFolder(root=train_path,\n",
    "                         transform=train_transform,\n",
    "                         target_transform=None,\n",
    "                        is_valid_file = is_valid_image)\n",
    "\n",
    "    test_data = ImageFolder(root=test_path,\n",
    "                         transform=train_transform,\n",
    "                        is_valid_file = is_valid_image\n",
    "                        )\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b60f0-9fc4-4f09-9afd-50f1513082ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = get_data(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5a309-264a-4130-b96b-320103b3a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_index = train_data.class_to_idxlen(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20934d9-3804-4ffd-bdac-5acb5c7b5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c45f67-90eb-4852-bd9d-46d5b9109957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image():\n",
    "    img_path = Path(train_path)\n",
    "    img_list = list(Path(train_path).glob(\"*/*.jpg\"))\n",
    "    random_img = random.choice(img_list)\n",
    "    img_class = random_img.parent.stem\n",
    "    print(\"Image Path: {}\".format(random_img))\n",
    "    print(\"image Class: {}\".format(img_class))\n",
    "    img = Image.open(random_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d90893-caf9-4b00-adc8-241a83e5f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20a06e-80c8-49ea-bdad-01e7266ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaders(train_data, test_data):\n",
    "  train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "  test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22339c-032d-4fff-92d0-c7adbdd854b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = loaders(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce850c-965f-473f-b3da-9e46a3c620cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader) , len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7a0c3-a5e7-41c3-87ae-c56eeb4d57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38299a57-2d2c-4198-a599-288d1425d930",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fc5b3-472b-408b-ab49-f18c16ae525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2370cb-f4d6-46cc-82bb-1f52d6d01e43",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666642de-bfe9-4ed8-96aa-c0bd7bcfbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    " weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_v2_s(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a5a33-582c-495d-98ea-c6951d0365ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model=model,\n",
    "                  input_size=[32, 3, 384, 384],\n",
    "                  col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "                  col_width=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32956f27-a730-4a22-a9e8-73391146c637",
   "metadata": {},
   "source": [
    "## Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f1287-d9b3-4dd2-9a78-29ed0bad766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.features[-3:].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ef30d-5b78-4fd8-bf80-aee525f1a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "                        nn.Dropout(p=0.3, inplace=True),\n",
    "                        nn.Linear(1280, 512),\n",
    "                        nn.BatchNorm1d(512),\n",
    "                        nn.SiLU(inplace=True),\n",
    "                        nn.Dropout(p=0.2),\n",
    "                        nn.Linear(in_features=512,\n",
    "                                  out_features=2,\n",
    "                                  bias=True)\n",
    "                        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1082e16-6155-4fb6-855e-13e02f60797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model=model,\n",
    "                  input_size=[32, 3, 384, 384],\n",
    "                  col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "                  col_width=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cffce7-1ecb-45a5-8e47-f0c05867df14",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadebcf4-bc3e-48f0-a050-ab8b89b0a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8eaf77-9d8b-4811-9391-7e4190b311e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0.0, 0.0\n",
    "    scaler = torch.cuda.amp.GradScaler()  # Initialize scaler\n",
    "\n",
    "    for batch, (img, label) in enumerate(dataloader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Mixed precision forward\n",
    "          prediction = model(img)\n",
    "          loss = loss_fn(prediction, label)\n",
    "\n",
    "        scaler.scale(loss).backward() # Scale gradients\n",
    "        scaler.step(optimizer)    # Update weights\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        pred_class = prediction.argmax(dim=1)\n",
    "        train_accuracy += accuracy_fn(y_true = label, y_pred = pred_class)\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_accuracy = train_accuracy / len(dataloader)\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0180d62-c5ee-4542-a0ee-c9e6c8dec948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step( model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy = 0.0, 0.0\n",
    "    for batch, (img, label) in enumerate(dataloader):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        prediction = model(img)\n",
    "        loss = loss_fn(prediction, label)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        pred_class = prediction.argmax(dim=1)\n",
    "        test_accuracy += accuracy_fn(y_true = label, y_pred = pred_class)\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_accuracy = test_accuracy / len(dataloader)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa8e81-6c5e-4cdf-aa2b-8bb2fced8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:torch.nn.Module,\n",
    "                train_loader: torch.utils.data.DataLoader,\n",
    "                test_loader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                num_epochs: int,\n",
    "                device: torch.device,\n",
    "                save_step: int = 5,\n",
    "                first_epoch: int = 0,\n",
    "                model_name: str= \"EfficientNet_V2\"\n",
    "               ) -> Dict[str, List]:\n",
    "\n",
    "    writer = SummaryWriter(\"tb_loggers\")\n",
    "    model = model\n",
    "\n",
    "    root_path = f\"saved_models/{model_name}\"\n",
    "    os.makedirs(root_path, exist_ok = True)\n",
    "\n",
    "    #load model\n",
    "    if first_epoch >= 1:\n",
    "        checkpoint_path = os.path.join(root_path, f\"model_{model_name}_{first_epoch}.pth\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        best_accuracy = checkpoint.get(\"best_accuracy\", 0.0)\n",
    "        print(f\"Resuming Training from epoch {first_epoch}, best accuracy so far: {best_accuracy:.4f}\")\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in tqdm(range(first_epoch+1, num_epochs+1), total=num_epochs, initial=first_epoch):\n",
    "        path_to_save = os.path.join(root_path, f\"model_{model_name}_{epoch}.pth\")\n",
    "        path_to_save_best_model = os.path.join(root_path, \"best_model.pth\")\n",
    "\n",
    "        start_train = time.time()\n",
    "        train_loss, train_accuracy = train_step(model = model,\n",
    "                                               dataloader = train_loader,\n",
    "                                               loss_fn = loss_fn,\n",
    "                                               optimizer = optimizer,\n",
    "                                               device = device)\n",
    "        end_train = time.time()\n",
    "\n",
    "        start_test = time.time()\n",
    "        test_loss, test_accuracy = test_step(  model = model,\n",
    "                                               dataloader = test_loader,\n",
    "                                               loss_fn = loss_fn,\n",
    "                                               device = device)\n",
    "        end_test = time.time()\n",
    "        scheduler.step(test_accuracy)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | \"\n",
    "            f\"Training Loss: {train_loss:.4f} | \"\n",
    "            f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
    "            f\"Training Time: {end_train - start_train:.3f} ||\"\n",
    "            f\"Test Loss: {test_loss:.4f} | \"\n",
    "            f\"Test Accuracy: {test_accuracy:.4f} | \"\n",
    "            f\"Testing Time: {end_test - start_test:.3f}\"\n",
    "        )\n",
    "\n",
    "        # save loss and accuracy\n",
    "        # results[\"train_loss\"].append(train_loss)\n",
    "        # results[\"train_accuracy\"].append(train_accuracy)\n",
    "        # results[\"test_loss\"].append(test_loss)\n",
    "        # results[\"test_accuracy\"].append(test_accuracy)\n",
    "\n",
    "        # save model\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(\n",
    "                {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_accuracy\": best_accuracy,\n",
    "                },\n",
    "                path_to_save_best_model)\n",
    "\n",
    "            print(\"Model saved at {}\".format(path_to_save))\n",
    "            print(\"=\"*100)\n",
    "\n",
    "        if epoch % save_step == 0:\n",
    "            torch.save(\n",
    "                {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_accuracy\": best_accuracy,\n",
    "                }, path_to_save)\n",
    "\n",
    "          # log to tensorboard\n",
    "            writer.add_scalar(\"Loss/train\", train_loss, epoch, walltime=True)\n",
    "            writer.add_scalar(\"Accuracy/train\", train_accuracy, epoch, walltime=True)\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch, walltime=True)\n",
    "            writer.add_scalar(\"Accuracy/test\", test_accuracy, epoch, walltime=True)\n",
    "    writer.close()\n",
    "    return #results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cfcd2-8635-44b3-ba51-a53fe95cb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3a900-a3c1-4153-aee9-5f70a89e55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d7937-1871-42b4-a9bf-98df99e06d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_model(model = model,\n",
    "                    train_loader = train_loader ,\n",
    "                    test_loader = test_loader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer,\n",
    "                    num_epochs = num_epochs,\n",
    "                    first_epoch = 0,\n",
    "                    save_step = 5,\n",
    "                    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21d622-99c2-4699-83ed-8c354b616346",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e2fe8-1190-45d9-8f69-f36748a1be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67469d66-96b1-4127-9b20-1663981e1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "  weights = torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "  model = torchvision.models.efficientnet_v2_s(weights=weights).to(device)\n",
    "\n",
    "  for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "  for param in model.features[-3:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "  model.classifier = nn.Sequential(\n",
    "                        nn.Dropout(p=0.3, inplace=True),\n",
    "                        nn.Linear(1280, 512),\n",
    "                        nn.BatchNorm1d(512),\n",
    "                        nn.SiLU(inplace=True),\n",
    "                        nn.Dropout(p=0.2),\n",
    "                        nn.Linear(in_features=512,\n",
    "                                  out_features=2,\n",
    "                                  bias=True)\n",
    "                        ).to(device)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea3149-66a9-4929-a484-911cc19e9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_inference(image_path):\n",
    "      image = Image.open(image_path)\n",
    "    \n",
    "      transform = transforms.Compose([\n",
    "      transforms.Resize((384, 384)),\n",
    "      transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "      transformed_image = transform(image)\n",
    "      transformed_image = transformed_image.unsqueeze(0)\n",
    "    \n",
    "      return transformed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f4ca4-bb6c-4088-844a-ef74d945e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, model_checkpoint, image_path):\n",
    "  checkpoint = torch.load(model_checkpoint, map_location=\"cpu\")\n",
    "  model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "  image = image_to_inference(image_path)\n",
    "\n",
    "  with inference_mode():\n",
    "    model.eval()\n",
    "    prediction = model(image)\n",
    "    prediction = prediction.argmax(dim=1)\n",
    "\n",
    "    class_name = class_names[prediction]\n",
    "    print(f\"Prediction: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cec6e8-8330-4af6-9801-e43bf0b9e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint=\"./saved_models/EfficientNet_V2/best_model.pth\"\n",
    "# image_path=\"./data/data/test/Cat/001.jpg\"\n",
    "image_path=\"./data/data/test/Dog/001.jpg\"\n",
    "inference(model=get_model(), model_checkpoint=model_checkpoint, image_path=image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
