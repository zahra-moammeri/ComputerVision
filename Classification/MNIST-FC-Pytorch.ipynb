{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuMLdhLa8D8k",
        "outputId": "65e9385a-5b75-4cc2-ed6b-f59b325985a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GO5i1nCF8z-i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "palv-l_4Wet4"
      },
      "source": [
        "# Create Fully Connected Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqFOt1rcT2CZ"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(NN,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, 50)\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paO29AIzYtN9",
        "outputId": "408ce48f-6e39-4e7f-c24e-3fb95241abb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = NN(784, 10)\n",
        "x =torch.randn(64, 784)\n",
        "model(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9q3aILhZ6Xd"
      },
      "source": [
        "# Set Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks_rM6fsZ9F9",
        "outputId": "0dc7ef07-f3d7-4ef2-c2d2-5149e9db44f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device= torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpbaIyLqcRmC"
      },
      "source": [
        "# HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzMQgfpLcUhi"
      },
      "outputs": [],
      "source": [
        "input_size= 784\n",
        "num_classes = 10\n",
        "learning_rate= 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTxmmhwwcmNL"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTwetXjzcobS",
        "outputId": "216697f3-e44a-4dfe-d4a1-482421b28f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 117153290.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/MNIST/raw/train-images-idx3-ubyte.gz to datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 70591896.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/MNIST/raw/train-labels-idx1-ubyte.gz to datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31224677.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23346236.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to datasets/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.MNIST(root='datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f23jdBs3dWqB"
      },
      "source": [
        "# Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR97yBoFdZpT"
      },
      "outputs": [],
      "source": [
        "model = NN(input_size= input_size, num_classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQUkiq74eLG7"
      },
      "source": [
        "# Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOn73DZFeOo6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsbteHKYfTsw"
      },
      "source": [
        "# Train Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdq2ghJofWZZ"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for data_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "    # get data to cuda if possible\n",
        "    data = data.to(device = device)\n",
        "    target = target.to(device = device)\n",
        "\n",
        "    # get to correct shape\n",
        "    data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "    # forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, target)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad() # Essentially set all the gradients to zero for each batch\n",
        "    loss.backward()\n",
        "\n",
        "    # gradient descent or adam step\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQTLnkwrrCBf"
      },
      "source": [
        "# Chech Accuracy on training and testing to see how good our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OED43a2jrNh4"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model):\n",
        "\n",
        "  if loader.dataset.train:\n",
        "    print('Checking Accuracy of train data: ')\n",
        "  else:\n",
        "    print('Checking Accuracy of test data: ')\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # We don't have to compute the gradient that would be unnessessory computing\n",
        "    for x, y in loader:\n",
        "      x = x.to(device= device)\n",
        "      y = y.to(device = device)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "      _, predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
        "  model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNgIMVKfvBNF",
        "outputId": "c2984d46-e16d-42af-d1a8-ff22d6ac23b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking Accuracy of train data: \n",
            "Got 55782 / 60000 with accuracy 92.97\n",
            "Checking Accuracy of test data: \n",
            "Got 9284 / 10000 with accuracy 92.84\n"
          ]
        }
      ],
      "source": [
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}